{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe754508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb8e6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_num = [\n",
    "    'Total_flux', 'Peak_flux', \n",
    "       'NUV_flux_corr', 'u_flux_corr', 'Bw_flux_corr', 'R_flux_corr',\n",
    "       'I_flux_corr', 'z_flux_corr', 'y_flux_corr',\n",
    "       'J_flux_corr', 'H_flux_corr', 'K_flux_corr', 'Ks_flux_corr',\n",
    "       'ch1_flux_corr', 'ch2_flux_corr', 'ch3_flux_corr', 'ch4_flux_corr',\n",
    "       'F_MIPS_24', 'F_PACS_100', 'F_PACS_160', 'F_SPIRE_250', 'F_SPIRE_350',\n",
    "       'F_SPIRE_500', 'Z_BEST',\n",
    "       'g_flux_corr', 'nb921_hsc_flux_corr'\n",
    "    ]\n",
    "y_column = \"Classification\"\n",
    "\n",
    "classes = ['jet-mode radio AGN/low-excitation radio galaxy', 'quasar-like radio AGN / high-excitation radio galaxy', \n",
    "           'radio-quiet AGN', 'star-forming galaxy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f3ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../../Data/Fangyou_data/Cleaned/combined_using_similar_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6d483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features_num]\n",
    "y = data[[y_column, 'Source']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1abca",
   "metadata": {},
   "source": [
    "# Adding 2 class columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a8d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGN(row):\n",
    "    \n",
    "    if row['Classification'] == 'jet-mode radio AGN/low-excitation radio galaxy':\n",
    "        return 1\n",
    "    elif row['Classification'] == 'quasar-like radio AGN / high-excitation radio galaxy':\n",
    "        return 1\n",
    "    elif row['Classification'] == 'radio-quiet AGN':\n",
    "        return 1\n",
    "    elif row['Classification'] == 'star-forming galaxy':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65902513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/lib/condor/execute/dir_1357265/ipykernel_1357405/1941264152.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['AGN'] =  y.apply(AGN, axis=1, result_type='expand')\n"
     ]
    }
   ],
   "source": [
    "# Temporarily relabelling it for function\n",
    "y['AGN'] =  y.apply(AGN, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8168f8a",
   "metadata": {},
   "source": [
    "## Making subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2be6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_elais = X[y['Source']=='Elais-N1']\n",
    "y_elais = y[y['Source']=='Elais-N1']\n",
    "\n",
    "X_lockman = X[y['Source']=='Lockman']\n",
    "y_lockman = y[y['Source']=='Lockman']\n",
    "\n",
    "X_bootes = X[y['Source']=='Bootes']\n",
    "y_bootes = y[y['Source']=='Bootes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfa2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X_lockman, X_elais])\n",
    "y_combined = pd.concat([y_lockman, y_elais])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e90f0e",
   "metadata": {},
   "source": [
    "## Adding noisy samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8670bd",
   "metadata": {},
   "source": [
    "## Converting PACS and SPIRE quartiles to stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aebc4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sigma_columns_u = ['FErr_MIPS_24_u', 'FErr_PACS_100_u', 'FErr_PACS_160_u', \n",
    "                     'FErr_SPIRE_250_u', 'FErr_SPIRE_350_u', 'FErr_SPIRE_500_u']\n",
    "non_sigma_columns_l = ['FErr_MIPS_24_l', 'FErr_PACS_100_l', 'FErr_PACS_160_l', \n",
    "                     'FErr_SPIRE_250_l', 'FErr_SPIRE_350_l', 'FErr_SPIRE_500_l']\n",
    "non_sigma_columns_corresponding = ['F_MIPS_24', 'F_PACS_100', 'F_PACS_160', \n",
    "                                 'F_SPIRE_250', 'F_SPIRE_350', 'F_SPIRE_500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b29c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from 84th Percentile to 1 sigma and 16th percentile to 1 sigma and then taking the average\n",
    "for column1, column2, column3 in zip(non_sigma_columns_u, non_sigma_columns_l, non_sigma_columns_corresponding):\n",
    "    std1 = np.abs(data[column3] - data[column1])/0.9945\n",
    "    std2 = np.abs(X[column3] - data[column2])/0.9945\n",
    "    data[column3 + '_error'] = (std1+std2)/2\n",
    "    data = data.drop(columns=[column1, column2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed15155",
   "metadata": {},
   "source": [
    "## Making the noisy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d78500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ['Total_flux', 'Peak_flux', 'NUV_flux_corr', 'u_flux_corr',\n",
    "       'Bw_flux_corr', 'R_flux_corr', 'I_flux_corr', 'z_flux_corr',\n",
    "       'y_flux_corr', 'J_flux_corr', 'H_flux_corr', 'K_flux_corr',\n",
    "       'Ks_flux_corr', 'ch1_flux_corr', 'ch2_flux_corr', 'ch3_flux_corr',\n",
    "       'ch4_flux_corr', 'g_flux_corr',\n",
    "       'nb921_hsc_flux_corr', 'F_MIPS_24', 'F_PACS_100', 'F_PACS_160', 'F_SPIRE_250',\n",
    "       'F_SPIRE_350', 'F_SPIRE_500']\n",
    "noise=[\n",
    "        'E_Total_flux', 'E_Peak_flux',\n",
    "       'NUV_fluxerr_corr', 'u_fluxerr_corr', 'Bw_fluxerr_corr',\n",
    "       'R_fluxerr_corr', 'I_fluxerr_corr', 'z_fluxerr_corr', 'y_fluxerr_corr',\n",
    "       'J_fluxerr_corr', 'H_fluxerr_corr', 'K_fluxerr_corr', 'Ks_fluxerr_corr',\n",
    "       'ch1_fluxerr_corr', 'ch2_fluxerr_corr', 'ch3_fluxerr_corr',\n",
    "       'ch4_fluxerr_corr', 'g_fluxerr_corr', 'nb921_hsc_fluxerr_corr',\n",
    "       'F_MIPS_24_error', 'F_PACS_100_error', 'F_PACS_160_error',\n",
    "       'F_SPIRE_250_error', 'F_SPIRE_350_error', 'F_SPIRE_500_error',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d110c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(X, flux_column, error_column, sn_mult=1):\n",
    "    noise =  np.random.normal(0, sn_mult*X[error_column])\n",
    "    \n",
    "    # adding the noise\n",
    "    return X[flux_column] + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7854676",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled = data.copy()\n",
    "for c1, c2 in zip(signal, noise):\n",
    "        data_resampled[c1] = resample(data_resampled, c1, c2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1da2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lockman_resampled = data_resampled[data_resampled['Source']=='Lockman'][features_num]\n",
    "y_lockman_resampled = data_resampled[data_resampled['Source']=='Lockman'][[y_column, 'Source']]\n",
    "\n",
    "X_elais_resampled = data_resampled[data_resampled['Source']=='Elais-N1'][features_num]\n",
    "y_elais_resampled = data_resampled[data_resampled['Source']=='Elais-N1'][[y_column, 'Source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bffc475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_resampled = pd.concat([X_elais_resampled, X_lockman_resampled, X_combined])\n",
    "y_combined_resampled = pd.concat([y_elais_resampled, y_lockman_resampled, y_combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c027a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily relabelling it for function\n",
    "y_combined_resampled['AGN'] =  y_combined_resampled.apply(AGN, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38675a",
   "metadata": {},
   "source": [
    "# BH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea8656a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Heckman_data = pd.read_csv(\"../../../Data/Best&Heckman/BestHeckman+SDSS+wise+LOFAR_better_fixed_fluxes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "766684b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only selecting data with a classification\n",
    "Best_Heckman_data = Best_Heckman_data[Best_Heckman_data['Classification'] != 'Radio-loud AGN'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b2fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Heckman_X = Best_Heckman_data[[c for c in Best_Heckman_data.columns if c != 'Classification']]\n",
    "Best_Heckman_y = Best_Heckman_data[['Classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90d6aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Heckman_X = Best_Heckman_X[['Z_BEST', 'u_flux_corr',\n",
    "       'g_flux_corr', 'R_flux_corr', 'I_flux_corr', 'z_flux_corr', 'ch1_flux_corr', 'ch2_flux_corr',\n",
    "       'J_flux_corr', 'H_flux_corr', 'Ks_flux_corr', 'Peak_flux', 'Total_flux']]\n",
    "\n",
    "# Adding nans to missing columns\n",
    "Best_Heckman_X[['NUV_flux_corr', 'Bw_flux_corr', 'y_flux_corr', 'K_flux_corr', \n",
    "                'F_MIPS_24', 'F_PACS_100', 'F_PACS_160', 'F_SPIRE_250', 'F_SPIRE_350',\n",
    "                'F_SPIRE_500', 'nb921_hsc_flux_corr', 'ch3_flux_corr', 'ch4_flux_corr']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4caae600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column order\n",
    "Best_Heckman_X = Best_Heckman_X[features_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5332354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/lib/condor/execute/dir_1357265/ipykernel_1357405/4091958156.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Best_Heckman_y['AGN'] =  Best_Heckman_y.apply(AGN, axis=1, result_type='expand')\n"
     ]
    }
   ],
   "source": [
    "Best_Heckman_y['AGN'] =  Best_Heckman_y.apply(AGN, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba86b6",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a03331d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9072    0.8680    0.8872     12213\n",
      "           1     0.7332    0.8033    0.7667      5516\n",
      "\n",
      "    accuracy                         0.8479     17729\n",
      "   macro avg     0.8202    0.8357    0.8269     17729\n",
      "weighted avg     0.8530    0.8479    0.8497     17729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_bootes['AGN'], automl.predict(X_bootes), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf568b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e45fdf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Source</th>\n",
       "      <th>AGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47977</th>\n",
       "      <td>star-forming galaxy</td>\n",
       "      <td>Lockman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47978</th>\n",
       "      <td>star-forming galaxy</td>\n",
       "      <td>Lockman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47979</th>\n",
       "      <td>radio-quiet AGN</td>\n",
       "      <td>Lockman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47980</th>\n",
       "      <td>jet-mode radio AGN/low-excitation radio galaxy</td>\n",
       "      <td>Lockman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47981</th>\n",
       "      <td>star-forming galaxy</td>\n",
       "      <td>Lockman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47972</th>\n",
       "      <td>star-forming galaxy</td>\n",
       "      <td>Elais-N1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47973</th>\n",
       "      <td>star-forming galaxy</td>\n",
       "      <td>Elais-N1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47974</th>\n",
       "      <td>star-forming galaxy</td>\n",
       "      <td>Elais-N1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47975</th>\n",
       "      <td>jet-mode radio AGN/low-excitation radio galaxy</td>\n",
       "      <td>Elais-N1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47976</th>\n",
       "      <td>radio-quiet AGN</td>\n",
       "      <td>Elais-N1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59880 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Classification    Source  AGN\n",
       "47977                             star-forming galaxy   Lockman    0\n",
       "47978                             star-forming galaxy   Lockman    0\n",
       "47979                                 radio-quiet AGN   Lockman    1\n",
       "47980  jet-mode radio AGN/low-excitation radio galaxy   Lockman    1\n",
       "47981                             star-forming galaxy   Lockman    0\n",
       "...                                               ...       ...  ...\n",
       "47972                             star-forming galaxy  Elais-N1    0\n",
       "47973                             star-forming galaxy  Elais-N1    0\n",
       "47974                             star-forming galaxy  Elais-N1    0\n",
       "47975  jet-mode radio AGN/low-excitation radio galaxy  Elais-N1    1\n",
       "47976                                 radio-quiet AGN  Elais-N1    1\n",
       "\n",
       "[59880 rows x 3 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c66dee89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-27 15:23:10] {2390} INFO - task = classification\n",
      "INFO:flaml.automl:task = classification\n",
      "[flaml.automl: 02-27 15:23:10] {2392} INFO - Data split method: stratified\n",
      "INFO:flaml.automl:Data split method: stratified\n",
      "[flaml.automl: 02-27 15:23:10] {2396} INFO - Evaluation method: cv\n",
      "INFO:flaml.automl:Evaluation method: cv\n",
      "[flaml.automl: 02-27 15:23:10] {2465} INFO - Minimizing error metric: 1-macro_f1\n",
      "INFO:flaml.automl:Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl: 02-27 15:23:10] {2605} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "INFO:flaml.automl:List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl: 02-27 15:23:10] {2897} INFO - iteration 0, current learner lgbm\n",
      "INFO:flaml.automl:iteration 0, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:14] {3025} INFO - Estimated sufficient time budget=39420s. Estimated necessary time budget=909s.\n",
      "INFO:flaml.automl:Estimated sufficient time budget=39420s. Estimated necessary time budget=909s.\n",
      "[flaml.automl: 02-27 15:23:14] {3072} INFO -  at 4.6s,\testimator lgbm's best error=0.7786,\tbest estimator lgbm's best error=0.7786\n",
      "INFO:flaml.automl: at 4.6s,\testimator lgbm's best error=0.7786,\tbest estimator lgbm's best error=0.7786\n",
      "[flaml.automl: 02-27 15:23:14] {2897} INFO - iteration 1, current learner lgbm\n",
      "INFO:flaml.automl:iteration 1, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:18] {3072} INFO -  at 8.2s,\testimator lgbm's best error=0.7786,\tbest estimator lgbm's best error=0.7786\n",
      "INFO:flaml.automl: at 8.2s,\testimator lgbm's best error=0.7786,\tbest estimator lgbm's best error=0.7786\n",
      "[flaml.automl: 02-27 15:23:18] {2897} INFO - iteration 2, current learner lgbm\n",
      "INFO:flaml.automl:iteration 2, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:21] {3072} INFO -  at 11.6s,\testimator lgbm's best error=0.5235,\tbest estimator lgbm's best error=0.5235\n",
      "INFO:flaml.automl: at 11.6s,\testimator lgbm's best error=0.5235,\tbest estimator lgbm's best error=0.5235\n",
      "[flaml.automl: 02-27 15:23:21] {2897} INFO - iteration 3, current learner xgboost\n",
      "INFO:flaml.automl:iteration 3, current learner xgboost\n",
      "[flaml.automl: 02-27 15:23:26] {3072} INFO -  at 16.4s,\testimator xgboost's best error=0.6069,\tbest estimator lgbm's best error=0.5235\n",
      "INFO:flaml.automl: at 16.4s,\testimator xgboost's best error=0.6069,\tbest estimator lgbm's best error=0.5235\n",
      "[flaml.automl: 02-27 15:23:26] {2897} INFO - iteration 4, current learner lgbm\n",
      "INFO:flaml.automl:iteration 4, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:31] {3072} INFO -  at 21.2s,\testimator lgbm's best error=0.3841,\tbest estimator lgbm's best error=0.3841\n",
      "INFO:flaml.automl: at 21.2s,\testimator lgbm's best error=0.3841,\tbest estimator lgbm's best error=0.3841\n",
      "[flaml.automl: 02-27 15:23:31] {2897} INFO - iteration 5, current learner lgbm\n",
      "INFO:flaml.automl:iteration 5, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:34] {3072} INFO -  at 24.6s,\testimator lgbm's best error=0.3841,\tbest estimator lgbm's best error=0.3841\n",
      "INFO:flaml.automl: at 24.6s,\testimator lgbm's best error=0.3841,\tbest estimator lgbm's best error=0.3841\n",
      "[flaml.automl: 02-27 15:23:34] {2897} INFO - iteration 6, current learner lgbm\n",
      "INFO:flaml.automl:iteration 6, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:39] {3072} INFO -  at 29.6s,\testimator lgbm's best error=0.3740,\tbest estimator lgbm's best error=0.3740\n",
      "INFO:flaml.automl: at 29.6s,\testimator lgbm's best error=0.3740,\tbest estimator lgbm's best error=0.3740\n",
      "[flaml.automl: 02-27 15:23:39] {2897} INFO - iteration 7, current learner lgbm\n",
      "INFO:flaml.automl:iteration 7, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:44] {3072} INFO -  at 34.4s,\testimator lgbm's best error=0.3740,\tbest estimator lgbm's best error=0.3740\n",
      "INFO:flaml.automl: at 34.4s,\testimator lgbm's best error=0.3740,\tbest estimator lgbm's best error=0.3740\n",
      "[flaml.automl: 02-27 15:23:44] {2897} INFO - iteration 8, current learner lgbm\n",
      "INFO:flaml.automl:iteration 8, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:47] {3072} INFO -  at 38.0s,\testimator lgbm's best error=0.3740,\tbest estimator lgbm's best error=0.3740\n",
      "INFO:flaml.automl: at 38.0s,\testimator lgbm's best error=0.3740,\tbest estimator lgbm's best error=0.3740\n",
      "[flaml.automl: 02-27 15:23:47] {2897} INFO - iteration 9, current learner lgbm\n",
      "INFO:flaml.automl:iteration 9, current learner lgbm\n",
      "[flaml.automl: 02-27 15:23:57] {3072} INFO -  at 47.4s,\testimator lgbm's best error=0.3313,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 47.4s,\testimator lgbm's best error=0.3313,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:23:57] {2897} INFO - iteration 10, current learner xgboost\n",
      "INFO:flaml.automl:iteration 10, current learner xgboost\n",
      "[flaml.automl: 02-27 15:24:01] {3072} INFO -  at 52.2s,\testimator xgboost's best error=0.6069,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 52.2s,\testimator xgboost's best error=0.6069,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:01] {2897} INFO - iteration 11, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 11, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:24:02] {3072} INFO -  at 52.7s,\testimator extra_tree's best error=0.7887,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 52.7s,\testimator extra_tree's best error=0.7887,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:02] {2897} INFO - iteration 12, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 12, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:24:02] {3072} INFO -  at 53.1s,\testimator extra_tree's best error=0.7835,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 53.1s,\testimator extra_tree's best error=0.7835,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:02] {2897} INFO - iteration 13, current learner rf\n",
      "INFO:flaml.automl:iteration 13, current learner rf\n",
      "[flaml.automl: 02-27 15:24:07] {3072} INFO -  at 57.7s,\testimator rf's best error=0.6932,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 57.7s,\testimator rf's best error=0.6932,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:07] {2897} INFO - iteration 14, current learner rf\n",
      "INFO:flaml.automl:iteration 14, current learner rf\n",
      "[flaml.automl: 02-27 15:24:09] {3072} INFO -  at 60.1s,\testimator rf's best error=0.6397,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 60.1s,\testimator rf's best error=0.6397,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:09] {2897} INFO - iteration 15, current learner xgboost\n",
      "INFO:flaml.automl:iteration 15, current learner xgboost\n",
      "[flaml.automl: 02-27 15:24:14] {3072} INFO -  at 64.8s,\testimator xgboost's best error=0.5941,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 64.8s,\testimator xgboost's best error=0.5941,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:14] {2897} INFO - iteration 16, current learner lgbm\n",
      "INFO:flaml.automl:iteration 16, current learner lgbm\n",
      "[flaml.automl: 02-27 15:24:19] {3072} INFO -  at 69.6s,\testimator lgbm's best error=0.3313,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 69.6s,\testimator lgbm's best error=0.3313,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:19] {2897} INFO - iteration 17, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 17, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:24:19] {3072} INFO -  at 70.0s,\testimator extra_tree's best error=0.7835,\tbest estimator lgbm's best error=0.3313\n",
      "INFO:flaml.automl: at 70.0s,\testimator extra_tree's best error=0.7835,\tbest estimator lgbm's best error=0.3313\n",
      "[flaml.automl: 02-27 15:24:19] {2897} INFO - iteration 18, current learner lgbm\n",
      "INFO:flaml.automl:iteration 18, current learner lgbm\n",
      "[flaml.automl: 02-27 15:25:03] {3072} INFO -  at 113.3s,\testimator lgbm's best error=0.2845,\tbest estimator lgbm's best error=0.2845\n",
      "INFO:flaml.automl: at 113.3s,\testimator lgbm's best error=0.2845,\tbest estimator lgbm's best error=0.2845\n",
      "[flaml.automl: 02-27 15:25:03] {2897} INFO - iteration 19, current learner rf\n",
      "INFO:flaml.automl:iteration 19, current learner rf\n",
      "[flaml.automl: 02-27 15:25:05] {3072} INFO -  at 115.2s,\testimator rf's best error=0.6397,\tbest estimator lgbm's best error=0.2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.automl: at 115.2s,\testimator rf's best error=0.6397,\tbest estimator lgbm's best error=0.2845\n",
      "[flaml.automl: 02-27 15:25:05] {2897} INFO - iteration 20, current learner lgbm\n",
      "INFO:flaml.automl:iteration 20, current learner lgbm\n",
      "[flaml.automl: 02-27 15:26:05] {3072} INFO -  at 175.8s,\testimator lgbm's best error=0.2845,\tbest estimator lgbm's best error=0.2845\n",
      "INFO:flaml.automl: at 175.8s,\testimator lgbm's best error=0.2845,\tbest estimator lgbm's best error=0.2845\n",
      "[flaml.automl: 02-27 15:26:05] {2897} INFO - iteration 21, current learner rf\n",
      "INFO:flaml.automl:iteration 21, current learner rf\n",
      "[flaml.automl: 02-27 15:26:13] {3072} INFO -  at 184.2s,\testimator rf's best error=0.6397,\tbest estimator lgbm's best error=0.2845\n",
      "INFO:flaml.automl: at 184.2s,\testimator rf's best error=0.6397,\tbest estimator lgbm's best error=0.2845\n",
      "[flaml.automl: 02-27 15:26:13] {2897} INFO - iteration 22, current learner lgbm\n",
      "INFO:flaml.automl:iteration 22, current learner lgbm\n",
      "[flaml.automl: 02-27 15:26:47] {3072} INFO -  at 217.4s,\testimator lgbm's best error=0.2845,\tbest estimator lgbm's best error=0.2845\n",
      "INFO:flaml.automl: at 217.4s,\testimator lgbm's best error=0.2845,\tbest estimator lgbm's best error=0.2845\n",
      "[flaml.automl: 02-27 15:26:47] {2897} INFO - iteration 23, current learner lgbm\n",
      "INFO:flaml.automl:iteration 23, current learner lgbm\n",
      "[flaml.automl: 02-27 15:27:29] {3072} INFO -  at 259.2s,\testimator lgbm's best error=0.2797,\tbest estimator lgbm's best error=0.2797\n",
      "INFO:flaml.automl: at 259.2s,\testimator lgbm's best error=0.2797,\tbest estimator lgbm's best error=0.2797\n",
      "[flaml.automl: 02-27 15:27:29] {2897} INFO - iteration 24, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 24, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:27:29] {3072} INFO -  at 259.9s,\testimator extra_tree's best error=0.7835,\tbest estimator lgbm's best error=0.2797\n",
      "INFO:flaml.automl: at 259.9s,\testimator extra_tree's best error=0.7835,\tbest estimator lgbm's best error=0.2797\n",
      "[flaml.automl: 02-27 15:27:29] {2897} INFO - iteration 25, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 25, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:27:30] {3072} INFO -  at 260.3s,\testimator extra_tree's best error=0.7644,\tbest estimator lgbm's best error=0.2797\n",
      "INFO:flaml.automl: at 260.3s,\testimator extra_tree's best error=0.7644,\tbest estimator lgbm's best error=0.2797\n",
      "[flaml.automl: 02-27 15:27:30] {2897} INFO - iteration 26, current learner rf\n",
      "INFO:flaml.automl:iteration 26, current learner rf\n",
      "[flaml.automl: 02-27 15:27:34] {3072} INFO -  at 264.7s,\testimator rf's best error=0.5684,\tbest estimator lgbm's best error=0.2797\n",
      "INFO:flaml.automl: at 264.7s,\testimator rf's best error=0.5684,\tbest estimator lgbm's best error=0.2797\n",
      "[flaml.automl: 02-27 15:27:34] {2897} INFO - iteration 27, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 27, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:27:35] {3072} INFO -  at 265.4s,\testimator extra_tree's best error=0.7644,\tbest estimator lgbm's best error=0.2797\n",
      "INFO:flaml.automl: at 265.4s,\testimator extra_tree's best error=0.7644,\tbest estimator lgbm's best error=0.2797\n",
      "[flaml.automl: 02-27 15:27:35] {2897} INFO - iteration 28, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 28, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:27:35] {3072} INFO -  at 265.9s,\testimator extra_tree's best error=0.7292,\tbest estimator lgbm's best error=0.2797\n",
      "INFO:flaml.automl: at 265.9s,\testimator extra_tree's best error=0.7292,\tbest estimator lgbm's best error=0.2797\n",
      "[flaml.automl: 02-27 15:27:35] {2897} INFO - iteration 29, current learner extra_tree\n",
      "INFO:flaml.automl:iteration 29, current learner extra_tree\n",
      "[flaml.automl: 02-27 15:27:37] {3072} INFO -  at 267.2s,\testimator extra_tree's best error=0.7263,\tbest estimator lgbm's best error=0.2797\n",
      "INFO:flaml.automl: at 267.2s,\testimator extra_tree's best error=0.7263,\tbest estimator lgbm's best error=0.2797\n",
      "[flaml.automl: 02-27 15:27:37] {2897} INFO - iteration 30, current learner lgbm\n",
      "INFO:flaml.automl:iteration 30, current learner lgbm\n",
      "[flaml.automl: 02-27 15:28:19] {3072} INFO -  at 309.5s,\testimator lgbm's best error=0.2771,\tbest estimator lgbm's best error=0.2771\n",
      "INFO:flaml.automl: at 309.5s,\testimator lgbm's best error=0.2771,\tbest estimator lgbm's best error=0.2771\n",
      "[flaml.automl: 02-27 15:28:19] {2897} INFO - iteration 31, current learner lgbm\n",
      "INFO:flaml.automl:iteration 31, current learner lgbm\n",
      "[flaml.automl: 02-27 15:29:32] {3072} INFO -  at 382.5s,\testimator lgbm's best error=0.2771,\tbest estimator lgbm's best error=0.2771\n",
      "INFO:flaml.automl: at 382.5s,\testimator lgbm's best error=0.2771,\tbest estimator lgbm's best error=0.2771\n",
      "[flaml.automl: 02-27 15:29:32] {2897} INFO - iteration 32, current learner lgbm\n",
      "INFO:flaml.automl:iteration 32, current learner lgbm\n",
      "[flaml.automl: 02-27 15:30:03] {3072} INFO -  at 414.1s,\testimator lgbm's best error=0.2771,\tbest estimator lgbm's best error=0.2771\n",
      "INFO:flaml.automl: at 414.1s,\testimator lgbm's best error=0.2771,\tbest estimator lgbm's best error=0.2771\n",
      "[flaml.automl: 02-27 15:30:03] {2897} INFO - iteration 33, current learner xgboost\n",
      "INFO:flaml.automl:iteration 33, current learner xgboost\n",
      "[flaml.automl: 02-27 15:30:08] {3072} INFO -  at 419.0s,\testimator xgboost's best error=0.4675,\tbest estimator lgbm's best error=0.2771\n",
      "INFO:flaml.automl: at 419.0s,\testimator xgboost's best error=0.4675,\tbest estimator lgbm's best error=0.2771\n",
      "[flaml.automl: 02-27 15:30:08] {2897} INFO - iteration 34, current learner lgbm\n",
      "INFO:flaml.automl:iteration 34, current learner lgbm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/training_log.py\u001b[0m in \u001b[0;36mtraining_log_writer\u001b[0;34m(filename, append)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, early_stop, append_log, auto_augment, min_sample_size, use_ray, metric_constraints, custom_hp, fit_kwargs_by_estimator, **fit_kwargs)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2631\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36m_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3179\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_ray\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36m_search_sequential\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2997\u001b[0m             \u001b[0mstart_run_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2998\u001b[0;31m             analysis = tune.run(\n\u001b[0m\u001b[1;32m   2999\u001b[0m                 \u001b[0msearch_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_incumbent_result_in_evaluation, **ray_args)\u001b[0m\n\u001b[1;32m    506\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"trial {num_trials} config: {trial_to_run.config}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_to_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36m_compute_with_config_base\u001b[0;34m(config_w_resource, state, estimator)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mpred_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0msampled_X_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/ml.py\u001b[0m in \u001b[0;36mcompute_estimator\u001b[0;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         val_loss, metric_for_logging, train_time, pred_time = evaluate_model_CV(\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0mconfig_dic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/ml.py\u001b[0m in \u001b[0;36mevaluate_model_CV\u001b[0;34m(config, estimator, X_train_all, y_train_all, budget, kf, task, eval_metric, best_val_loss, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mgroups_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         val_loss_i, metric_i, train_time_i, pred_time_i = get_val_loss(\n\u001b[0m\u001b[1;32m    517\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/ml.py\u001b[0m in \u001b[0;36mget_val_loss\u001b[0;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, obj, labels, budget, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m#     fit_kwargs['y_val'] = y_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     val_loss, metric_for_logging, pred_time, _ = _eval_estimator(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, budget, **kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             self._fit(\n\u001b[0m\u001b[1;32m   1115\u001b[0m                 \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"flaml.model - {model} fit started\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[1;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/lib/condor/execute/dir_1357265/ipykernel_1357405/3526915496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     automl.fit(X, y['Classification'], task=\"classification\", metric='macro_f1',\n\u001b[0m\u001b[1;32m     10\u001b[0m                                 \u001b[0;31m#X_val=X_bootes , y_val=y_bootes['Classification'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 \u001b[0;31m#ensemble=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, early_stop, append_log, auto_augment, min_sample_size, use_ray, metric_constraints, custom_hp, fit_kwargs_by_estimator, **fit_kwargs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtraining_log_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_log\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2631\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/training_log.py\u001b[0m in \u001b[0;36mtraining_log_writer\u001b[0;34m(filename, append)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/flaml/training_log.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "estimators = ['xgb_limitdepth']\n",
    "#estimators = ['extra_tree']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    automl.fit(X, y['Classification'], task=\"classification\", metric='macro_f1',\n",
    "                                #X_val=X_bootes , y_val=y_bootes['Classification'],\n",
    "                                #ensemble=True,\n",
    "                                #estimator_list=['xgboost'], \n",
    "                                time_budget=600, n_jobs=8,\n",
    "                                #eval_method='cv',\n",
    "                                log_file_name='general.log',\n",
    "                                #starting_points=automl.best_config_per_estimator\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3a1ad14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/users/karsten/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "      jet-mode radio AGN/low-excitation radio galaxy     0.7792    0.8576    0.8166      9771\n",
      "quasar-like radio AGN / high-excitation radio galaxy     0.0000    0.0000    0.0000       478\n",
      "                                 star-forming galaxy     0.3875    0.3203    0.3507      2913\n",
      "\n",
      "                                            accuracy                         0.7076     13162\n",
      "                                           macro avg     0.3889    0.3926    0.3891     13162\n",
      "                                        weighted avg     0.6642    0.7076    0.6838     13162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/users/karsten/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/users/karsten/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Best_Heckman_y['Classification'], automl.predict(Best_Heckman_X), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "cd28b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "712bcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    #'n_estimators': 189,\n",
    "    'n_estimators': 10**5,\n",
    "  'num_leaves': 20,\n",
    "  'min_child_samples': 6,\n",
    "  'learning_rate': 0.06500463168967072,\n",
    "  'colsample_bytree': 0.6649148062238498,\n",
    "  'reg_alpha': 0.0009765625,\n",
    "  'reg_lambda': 0.004681547467007761\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a876ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_combined, label=y_combined['AGN'])\n",
    "validation_data = lgb.Dataset(X_bootes, label=y_bootes['AGN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "eb3af7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/users/karsten/.local/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/users/karsten/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 59880, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 0.258066\n",
      "[1]\ttraining's l2: 0.182898\tvalid_1's l2: 0.206177\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's l2: 0.174888\tvalid_1's l2: 0.196376\n",
      "[3]\ttraining's l2: 0.167218\tvalid_1's l2: 0.187074\n",
      "[4]\ttraining's l2: 0.1618\tvalid_1's l2: 0.18071\n",
      "[5]\ttraining's l2: 0.156236\tvalid_1's l2: 0.174203\n",
      "[6]\ttraining's l2: 0.150885\tvalid_1's l2: 0.167528\n",
      "[7]\ttraining's l2: 0.146085\tvalid_1's l2: 0.162764\n",
      "[8]\ttraining's l2: 0.142183\tvalid_1's l2: 0.158223\n",
      "[9]\ttraining's l2: 0.138345\tvalid_1's l2: 0.153657\n",
      "[10]\ttraining's l2: 0.133933\tvalid_1's l2: 0.148977\n",
      "[11]\ttraining's l2: 0.131114\tvalid_1's l2: 0.146476\n",
      "[12]\ttraining's l2: 0.127548\tvalid_1's l2: 0.14297\n",
      "[13]\ttraining's l2: 0.124526\tvalid_1's l2: 0.140383\n",
      "[14]\ttraining's l2: 0.121772\tvalid_1's l2: 0.137662\n",
      "[15]\ttraining's l2: 0.119364\tvalid_1's l2: 0.135448\n",
      "[16]\ttraining's l2: 0.117203\tvalid_1's l2: 0.133371\n",
      "[17]\ttraining's l2: 0.115231\tvalid_1's l2: 0.132158\n",
      "[18]\ttraining's l2: 0.113295\tvalid_1's l2: 0.130497\n",
      "[19]\ttraining's l2: 0.111507\tvalid_1's l2: 0.128905\n",
      "[20]\ttraining's l2: 0.109667\tvalid_1's l2: 0.127169\n",
      "[21]\ttraining's l2: 0.107944\tvalid_1's l2: 0.12557\n",
      "[22]\ttraining's l2: 0.106333\tvalid_1's l2: 0.124583\n",
      "[23]\ttraining's l2: 0.105102\tvalid_1's l2: 0.123744\n",
      "[24]\ttraining's l2: 0.103768\tvalid_1's l2: 0.123048\n",
      "[25]\ttraining's l2: 0.102635\tvalid_1's l2: 0.122143\n",
      "[26]\ttraining's l2: 0.101591\tvalid_1's l2: 0.121373\n",
      "[27]\ttraining's l2: 0.100374\tvalid_1's l2: 0.120652\n",
      "[28]\ttraining's l2: 0.0990784\tvalid_1's l2: 0.119777\n",
      "[29]\ttraining's l2: 0.0982128\tvalid_1's l2: 0.118982\n",
      "[30]\ttraining's l2: 0.0973288\tvalid_1's l2: 0.118673\n",
      "[31]\ttraining's l2: 0.0964495\tvalid_1's l2: 0.118181\n",
      "[32]\ttraining's l2: 0.0956884\tvalid_1's l2: 0.117665\n",
      "[33]\ttraining's l2: 0.0949475\tvalid_1's l2: 0.11729\n",
      "[34]\ttraining's l2: 0.0942343\tvalid_1's l2: 0.116995\n",
      "[35]\ttraining's l2: 0.0935995\tvalid_1's l2: 0.116553\n",
      "[36]\ttraining's l2: 0.0928213\tvalid_1's l2: 0.115974\n",
      "[37]\ttraining's l2: 0.0921352\tvalid_1's l2: 0.115605\n",
      "[38]\ttraining's l2: 0.0915702\tvalid_1's l2: 0.115569\n",
      "[39]\ttraining's l2: 0.0910991\tvalid_1's l2: 0.115385\n",
      "[40]\ttraining's l2: 0.0905427\tvalid_1's l2: 0.115218\n",
      "[41]\ttraining's l2: 0.0901096\tvalid_1's l2: 0.115462\n",
      "[42]\ttraining's l2: 0.089703\tvalid_1's l2: 0.115454\n",
      "[43]\ttraining's l2: 0.0892019\tvalid_1's l2: 0.115222\n",
      "[44]\ttraining's l2: 0.0887099\tvalid_1's l2: 0.115007\n",
      "[45]\ttraining's l2: 0.0881737\tvalid_1's l2: 0.114737\n",
      "[46]\ttraining's l2: 0.0878477\tvalid_1's l2: 0.114706\n",
      "[47]\ttraining's l2: 0.0872599\tvalid_1's l2: 0.114378\n",
      "[48]\ttraining's l2: 0.0868072\tvalid_1's l2: 0.114108\n",
      "[49]\ttraining's l2: 0.0863887\tvalid_1's l2: 0.114003\n",
      "[50]\ttraining's l2: 0.0861074\tvalid_1's l2: 0.11398\n",
      "[51]\ttraining's l2: 0.0857777\tvalid_1's l2: 0.113911\n",
      "[52]\ttraining's l2: 0.0854772\tvalid_1's l2: 0.113897\n",
      "[53]\ttraining's l2: 0.0851762\tvalid_1's l2: 0.113834\n",
      "[54]\ttraining's l2: 0.0848424\tvalid_1's l2: 0.113765\n",
      "[55]\ttraining's l2: 0.0844595\tvalid_1's l2: 0.114128\n",
      "[56]\ttraining's l2: 0.0841625\tvalid_1's l2: 0.114182\n",
      "[57]\ttraining's l2: 0.0839315\tvalid_1's l2: 0.114105\n",
      "[58]\ttraining's l2: 0.0836774\tvalid_1's l2: 0.113968\n",
      "[59]\ttraining's l2: 0.0833845\tvalid_1's l2: 0.113804\n",
      "[60]\ttraining's l2: 0.0830987\tvalid_1's l2: 0.113675\n",
      "[61]\ttraining's l2: 0.0828286\tvalid_1's l2: 0.113534\n",
      "[62]\ttraining's l2: 0.0825435\tvalid_1's l2: 0.113311\n",
      "[63]\ttraining's l2: 0.08231\tvalid_1's l2: 0.113177\n",
      "[64]\ttraining's l2: 0.0821345\tvalid_1's l2: 0.113244\n",
      "[65]\ttraining's l2: 0.0819471\tvalid_1's l2: 0.113199\n",
      "[66]\ttraining's l2: 0.0816644\tvalid_1's l2: 0.113105\n",
      "[67]\ttraining's l2: 0.0814172\tvalid_1's l2: 0.112993\n",
      "[68]\ttraining's l2: 0.0811622\tvalid_1's l2: 0.112951\n",
      "[69]\ttraining's l2: 0.0810011\tvalid_1's l2: 0.113011\n",
      "[70]\ttraining's l2: 0.0807393\tvalid_1's l2: 0.112868\n",
      "[71]\ttraining's l2: 0.0805424\tvalid_1's l2: 0.112744\n",
      "[72]\ttraining's l2: 0.0803888\tvalid_1's l2: 0.112731\n",
      "[73]\ttraining's l2: 0.0801737\tvalid_1's l2: 0.112574\n",
      "[74]\ttraining's l2: 0.0799641\tvalid_1's l2: 0.112541\n",
      "[75]\ttraining's l2: 0.079782\tvalid_1's l2: 0.11267\n",
      "[76]\ttraining's l2: 0.0795897\tvalid_1's l2: 0.112578\n",
      "[77]\ttraining's l2: 0.0794322\tvalid_1's l2: 0.112623\n",
      "[78]\ttraining's l2: 0.0792711\tvalid_1's l2: 0.11255\n",
      "[79]\ttraining's l2: 0.0791222\tvalid_1's l2: 0.112521\n",
      "[80]\ttraining's l2: 0.0789466\tvalid_1's l2: 0.1124\n",
      "[81]\ttraining's l2: 0.078845\tvalid_1's l2: 0.112292\n",
      "[82]\ttraining's l2: 0.0787247\tvalid_1's l2: 0.11257\n",
      "[83]\ttraining's l2: 0.0785915\tvalid_1's l2: 0.11255\n",
      "[84]\ttraining's l2: 0.0784817\tvalid_1's l2: 0.112469\n",
      "[85]\ttraining's l2: 0.0782848\tvalid_1's l2: 0.112798\n",
      "[86]\ttraining's l2: 0.0781427\tvalid_1's l2: 0.112711\n",
      "[87]\ttraining's l2: 0.0780442\tvalid_1's l2: 0.112668\n",
      "[88]\ttraining's l2: 0.0779614\tvalid_1's l2: 0.112354\n",
      "[89]\ttraining's l2: 0.0778745\tvalid_1's l2: 0.112354\n",
      "[90]\ttraining's l2: 0.0777599\tvalid_1's l2: 0.112265\n",
      "[91]\ttraining's l2: 0.0776436\tvalid_1's l2: 0.112208\n",
      "[92]\ttraining's l2: 0.0774892\tvalid_1's l2: 0.112049\n",
      "[93]\ttraining's l2: 0.0774075\tvalid_1's l2: 0.11185\n",
      "[94]\ttraining's l2: 0.0773417\tvalid_1's l2: 0.111862\n",
      "[95]\ttraining's l2: 0.0771838\tvalid_1's l2: 0.111794\n",
      "[96]\ttraining's l2: 0.0770461\tvalid_1's l2: 0.111667\n",
      "[97]\ttraining's l2: 0.0769786\tvalid_1's l2: 0.111629\n",
      "[98]\ttraining's l2: 0.0768679\tvalid_1's l2: 0.111827\n",
      "[99]\ttraining's l2: 0.0767943\tvalid_1's l2: 0.111927\n",
      "[100]\ttraining's l2: 0.0767117\tvalid_1's l2: 0.111917\n",
      "[101]\ttraining's l2: 0.0766405\tvalid_1's l2: 0.111838\n",
      "[102]\ttraining's l2: 0.0765192\tvalid_1's l2: 0.111872\n",
      "[103]\ttraining's l2: 0.0763743\tvalid_1's l2: 0.112132\n",
      "[104]\ttraining's l2: 0.0762689\tvalid_1's l2: 0.112158\n",
      "[105]\ttraining's l2: 0.0761166\tvalid_1's l2: 0.111915\n",
      "[106]\ttraining's l2: 0.076028\tvalid_1's l2: 0.111818\n",
      "[107]\ttraining's l2: 0.0759486\tvalid_1's l2: 0.111704\n",
      "[108]\ttraining's l2: 0.0757968\tvalid_1's l2: 0.1116\n",
      "[109]\ttraining's l2: 0.075731\tvalid_1's l2: 0.1116\n",
      "[110]\ttraining's l2: 0.0756589\tvalid_1's l2: 0.111563\n",
      "[111]\ttraining's l2: 0.0755864\tvalid_1's l2: 0.111636\n",
      "[112]\ttraining's l2: 0.0755261\tvalid_1's l2: 0.111648\n",
      "[113]\ttraining's l2: 0.0753608\tvalid_1's l2: 0.111568\n",
      "[114]\ttraining's l2: 0.0753027\tvalid_1's l2: 0.111545\n",
      "[115]\ttraining's l2: 0.0751659\tvalid_1's l2: 0.112347\n",
      "[116]\ttraining's l2: 0.0750977\tvalid_1's l2: 0.112307\n",
      "[117]\ttraining's l2: 0.0750268\tvalid_1's l2: 0.112288\n",
      "[118]\ttraining's l2: 0.0749372\tvalid_1's l2: 0.112378\n",
      "[119]\ttraining's l2: 0.0748799\tvalid_1's l2: 0.112435\n",
      "[120]\ttraining's l2: 0.0748003\tvalid_1's l2: 0.112427\n",
      "[121]\ttraining's l2: 0.0746699\tvalid_1's l2: 0.112405\n",
      "[122]\ttraining's l2: 0.0745905\tvalid_1's l2: 0.112343\n",
      "[123]\ttraining's l2: 0.0745009\tvalid_1's l2: 0.112342\n",
      "[124]\ttraining's l2: 0.074448\tvalid_1's l2: 0.112359\n",
      "[125]\ttraining's l2: 0.0742969\tvalid_1's l2: 0.112296\n",
      "[126]\ttraining's l2: 0.0741779\tvalid_1's l2: 0.112367\n",
      "[127]\ttraining's l2: 0.0741205\tvalid_1's l2: 0.112373\n",
      "[128]\ttraining's l2: 0.0740608\tvalid_1's l2: 0.11235\n",
      "[129]\ttraining's l2: 0.0739679\tvalid_1's l2: 0.112318\n",
      "[130]\ttraining's l2: 0.0738085\tvalid_1's l2: 0.112166\n",
      "[131]\ttraining's l2: 0.0736961\tvalid_1's l2: 0.112192\n",
      "[132]\ttraining's l2: 0.073617\tvalid_1's l2: 0.112179\n",
      "[133]\ttraining's l2: 0.0735636\tvalid_1's l2: 0.112123\n",
      "[134]\ttraining's l2: 0.0735063\tvalid_1's l2: 0.112087\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's l2: 0.0753027\tvalid_1's l2: 0.111545\n"
     ]
    }
   ],
   "source": [
    "bst = lgb.train(param, train_data, valid_sets=[train_data, validation_data], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4574e00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8443    0.5043    0.6314      2913\n",
      "           1     0.8736    0.9736    0.9209     10249\n",
      "\n",
      "    accuracy                         0.8697     13162\n",
      "   macro avg     0.8589    0.7389    0.7761     13162\n",
      "weighted avg     0.8671    0.8697    0.8568     13162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bst.predict(Best_Heckman_X)\n",
    "pred[pred>0.5]=1\n",
    "pred[pred<0.5]=0\n",
    "print(classification_report(Best_Heckman_y['AGN'], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "373e03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = ~Best_Heckman_X['Total_flux'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bootes_noradio = X_bootes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "94f24f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9089    0.8549    0.8811     12213\n",
      "           1     0.7161    0.8104    0.7603      5516\n",
      "\n",
      "    accuracy                         0.8411     17729\n",
      "   macro avg     0.8125    0.8326    0.8207     17729\n",
      "weighted avg     0.8489    0.8411    0.8435     17729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bst.predict(X_bootes)\n",
    "pred[pred>0.5]=1\n",
    "pred[pred<0.5]=0\n",
    "print(classification_report(y_bootes['AGN'], pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cf800",
   "metadata": {},
   "source": [
    "## Bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4843ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "params = {'verbose': -1}\n",
    "train_data = lgb.Dataset(X_combined, label=y_combined['AGN'], params=params, free_raw_data=False)\n",
    "validation_data = lgb.Dataset(X_bootes, label=y_bootes['AGN'], params=params, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3aeb36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_xgboost(num_leaves,\n",
    "                     learning_rate,\n",
    "                     colsample_bytree\n",
    "                    ):\n",
    "    num_leaves = int(num_leaves)\n",
    "    \n",
    "    param = {\n",
    "        'n_estimators': 10**5,\n",
    "      'num_leaves': num_leaves,\n",
    "      'learning_rate': learning_rate,\n",
    "      'colsample_bytree': colsample_bytree,\n",
    "      'verbose':-1\n",
    "    }\n",
    "    \n",
    "    # Training the model\n",
    "    bst = lgb.train(param, train_data, valid_sets=[validation_data], early_stopping_rounds=20, verbose_eval=False)\n",
    "\n",
    "    # Getting the accuracy and appending\n",
    "    pred = bst.predict(Best_Heckman_X)\n",
    "    \n",
    "    pred[pred>0.5]=1\n",
    "    pred[pred<0.5]=0\n",
    "\n",
    "    return f1_score(Best_Heckman_y['AGN'], pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8629972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounded region of parameter space\n",
    "pbounds = {\n",
    "    'num_leaves': (10, 50),\n",
    "    'learning_rate': (0.001, 0.8),\n",
    "    'colsample_bytree': (0.1,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0f8b7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=optimise_xgboost,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "204678f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | num_le... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.3781   \u001b[0m | \u001b[0m0.6963   \u001b[0m | \u001b[0m0.2501   \u001b[0m | \u001b[0m30.8     \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.3104   \u001b[0m | \u001b[0m0.592    \u001b[0m | \u001b[0m0.1487   \u001b[0m | \u001b[0m48.78    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.2415   \u001b[0m | \u001b[0m0.7976   \u001b[0m | \u001b[0m0.7517   \u001b[0m | \u001b[0m45.79    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.2254   \u001b[0m | \u001b[0m0.6381   \u001b[0m | \u001b[0m0.7376   \u001b[0m | \u001b[0m13.54    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.3826   \u001b[0m | \u001b[0m0.2764   \u001b[0m | \u001b[0m0.03714  \u001b[0m | \u001b[0m23.01    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.4498   \u001b[0m | \u001b[0m0.2178   \u001b[0m | \u001b[0m43.15    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.7098   \u001b[0m | \u001b[0m0.4211   \u001b[0m | \u001b[0m0.2255   \u001b[0m | \u001b[0m31.71    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.189    \u001b[0m | \u001b[0m0.2268   \u001b[0m | \u001b[0m0.642    \u001b[0m | \u001b[0m12.98    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.3214   \u001b[0m | \u001b[0m0.9882   \u001b[0m | \u001b[0m0.618    \u001b[0m | \u001b[0m17.95    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.4428   \u001b[0m | \u001b[0m0.105    \u001b[0m | \u001b[0m0.6526   \u001b[0m | \u001b[0m38.27    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.489    \u001b[0m | \u001b[0m0.2316   \u001b[0m | \u001b[0m0.06005  \u001b[0m | \u001b[0m37.38    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.2347   \u001b[0m | \u001b[0m0.3775   \u001b[0m | \u001b[0m0.689    \u001b[0m | \u001b[0m13.75    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.2414   \u001b[0m | \u001b[0m0.4106   \u001b[0m | \u001b[0m0.2947   \u001b[0m | \u001b[0m31.8     \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.5863   \u001b[0m | \u001b[0m0.3414   \u001b[0m | \u001b[0m0.205    \u001b[0m | \u001b[0m30.18    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.253    \u001b[0m | \u001b[0m0.6511   \u001b[0m | \u001b[0m0.05015  \u001b[0m | \u001b[0m26.99    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.5595   \u001b[0m | \u001b[0m0.6331   \u001b[0m | \u001b[0m0.576    \u001b[0m | \u001b[0m15.12    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.2631   \u001b[0m | \u001b[0m0.9511   \u001b[0m | \u001b[0m0.3617   \u001b[0m | \u001b[0m46.41    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.2248   \u001b[0m | \u001b[0m0.7125   \u001b[0m | \u001b[0m0.2837   \u001b[0m | \u001b[0m15.76    \u001b[0m |\n",
      "| \u001b[95m42       \u001b[0m | \u001b[95m0.7654   \u001b[0m | \u001b[95m0.4027   \u001b[0m | \u001b[95m0.04744  \u001b[0m | \u001b[95m45.14    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.4849   \u001b[0m | \u001b[0m0.8923   \u001b[0m | \u001b[0m0.6703   \u001b[0m | \u001b[0m22.83    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.2912   \u001b[0m | \u001b[0m0.3962   \u001b[0m | \u001b[0m0.7705   \u001b[0m | \u001b[0m30.21    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.6378   \u001b[0m | \u001b[0m0.7919   \u001b[0m | \u001b[0m0.06622  \u001b[0m | \u001b[0m35.54    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.617    \u001b[0m | \u001b[0m0.5741   \u001b[0m | \u001b[0m0.1778   \u001b[0m | \u001b[0m47.44    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.5569   \u001b[0m | \u001b[0m0.1633   \u001b[0m | \u001b[0m0.6248   \u001b[0m | \u001b[0m44.9     \u001b[0m |\n",
      "| \u001b[95m48       \u001b[0m | \u001b[95m0.7697   \u001b[0m | \u001b[95m0.2723   \u001b[0m | \u001b[95m0.3371   \u001b[0m | \u001b[95m45.34    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.3079   \u001b[0m | \u001b[0m0.6553   \u001b[0m | \u001b[0m0.03863  \u001b[0m | \u001b[0m43.78    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.4037   \u001b[0m | \u001b[0m0.832    \u001b[0m | \u001b[0m0.609    \u001b[0m | \u001b[0m36.21    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.5661   \u001b[0m | \u001b[0m0.3056   \u001b[0m | \u001b[0m0.1915   \u001b[0m | \u001b[0m16.29    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.1567   \u001b[0m | \u001b[0m0.2308   \u001b[0m | \u001b[0m35.54    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.306    \u001b[0m | \u001b[0m0.8623   \u001b[0m | \u001b[0m0.212    \u001b[0m | \u001b[0m31.07    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.4462   \u001b[0m | \u001b[0m0.152    \u001b[0m | \u001b[0m0.3638   \u001b[0m | \u001b[0m16.87    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.5353   \u001b[0m | \u001b[0m0.4064   \u001b[0m | \u001b[0m0.1823   \u001b[0m | \u001b[0m37.02    \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.2344   \u001b[0m | \u001b[0m0.5391   \u001b[0m | \u001b[0m0.1997   \u001b[0m | \u001b[0m18.63    \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.2071   \u001b[0m | \u001b[0m0.222    \u001b[0m | \u001b[0m0.7568   \u001b[0m | \u001b[0m14.02    \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.2756   \u001b[0m | \u001b[0m0.4156   \u001b[0m | \u001b[0m0.1082   \u001b[0m | \u001b[0m39.13    \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.2256   \u001b[0m | \u001b[0m0.7605   \u001b[0m | \u001b[0m0.7974   \u001b[0m | \u001b[0m27.99    \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.3012   \u001b[0m | \u001b[0m0.8008   \u001b[0m | \u001b[0m0.2557   \u001b[0m | \u001b[0m26.08    \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m0.3098   \u001b[0m | \u001b[0m0.7902   \u001b[0m | \u001b[0m0.1793   \u001b[0m | \u001b[0m18.2     \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m0.4483   \u001b[0m | \u001b[0m0.5394   \u001b[0m | \u001b[0m0.6412   \u001b[0m | \u001b[0m45.03    \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m0.2341   \u001b[0m | \u001b[0m0.5902   \u001b[0m | \u001b[0m0.3098   \u001b[0m | \u001b[0m14.53    \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m0.6182   \u001b[0m | \u001b[0m0.77     \u001b[0m | \u001b[0m0.2828   \u001b[0m | \u001b[0m24.83    \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m0.5716   \u001b[0m | \u001b[0m0.5577   \u001b[0m | \u001b[0m0.3421   \u001b[0m | \u001b[0m26.8     \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m0.2975   \u001b[0m | \u001b[0m0.9134   \u001b[0m | \u001b[0m0.09026  \u001b[0m | \u001b[0m18.67    \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m0.4318   \u001b[0m | \u001b[0m0.5551   \u001b[0m | \u001b[0m0.4309   \u001b[0m | \u001b[0m47.89    \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m0.3313   \u001b[0m | \u001b[0m0.806    \u001b[0m | \u001b[0m0.3554   \u001b[0m | \u001b[0m36.64    \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m0.5613   \u001b[0m | \u001b[0m0.3211   \u001b[0m | \u001b[0m0.7673   \u001b[0m | \u001b[0m37.54    \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m0.4926   \u001b[0m | \u001b[0m0.7843   \u001b[0m | \u001b[0m0.4889   \u001b[0m | \u001b[0m40.15    \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m0.3161   \u001b[0m | \u001b[0m0.9689   \u001b[0m | \u001b[0m0.7419   \u001b[0m | \u001b[0m13.24    \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m0.1926   \u001b[0m | \u001b[0m0.1924   \u001b[0m | \u001b[0m0.7579   \u001b[0m | \u001b[0m12.55    \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m0.2777   \u001b[0m | \u001b[0m0.8445   \u001b[0m | \u001b[0m0.3355   \u001b[0m | \u001b[0m19.51    \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m0.5778   \u001b[0m | \u001b[0m0.3346   \u001b[0m | \u001b[0m0.2185   \u001b[0m | \u001b[0m14.85    \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m0.235    \u001b[0m | \u001b[0m0.5331   \u001b[0m | \u001b[0m0.3638   \u001b[0m | \u001b[0m32.46    \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m0.2361   \u001b[0m | \u001b[0m0.8048   \u001b[0m | \u001b[0m0.4298   \u001b[0m | \u001b[0m45.97    \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m0.2711   \u001b[0m | \u001b[0m0.9108   \u001b[0m | \u001b[0m0.5659   \u001b[0m | \u001b[0m42.91    \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m0.5759   \u001b[0m | \u001b[0m0.2166   \u001b[0m | \u001b[0m0.02506  \u001b[0m | \u001b[0m48.46    \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m0.5574   \u001b[0m | \u001b[0m0.1657   \u001b[0m | \u001b[0m0.7479   \u001b[0m | \u001b[0m49.41    \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m0.1878   \u001b[0m | \u001b[0m0.2223   \u001b[0m | \u001b[0m0.3413   \u001b[0m | \u001b[0m17.71    \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m0.2729   \u001b[0m | \u001b[0m0.5623   \u001b[0m | \u001b[0m0.1313   \u001b[0m | \u001b[0m25.86    \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m0.2154   \u001b[0m | \u001b[0m0.937    \u001b[0m | \u001b[0m0.3965   \u001b[0m | \u001b[0m15.21    \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m0.2354   \u001b[0m | \u001b[0m0.949    \u001b[0m | \u001b[0m0.4888   \u001b[0m | \u001b[0m49.22    \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m0.2725   \u001b[0m | \u001b[0m0.9928   \u001b[0m | \u001b[0m0.7116   \u001b[0m | \u001b[0m35.95    \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.1328   \u001b[0m | \u001b[0m0.3984   \u001b[0m | \u001b[0m29.19    \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m0.5407   \u001b[0m | \u001b[0m0.2086   \u001b[0m | \u001b[0m0.127    \u001b[0m | \u001b[0m28.67    \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m0.2343   \u001b[0m | \u001b[0m0.5645   \u001b[0m | \u001b[0m0.4025   \u001b[0m | \u001b[0m13.0     \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m0.2257   \u001b[0m | \u001b[0m0.6431   \u001b[0m | \u001b[0m0.7729   \u001b[0m | \u001b[0m23.07    \u001b[0m |\n",
      "| \u001b[95m89       \u001b[0m | \u001b[95m0.7725   \u001b[0m | \u001b[95m0.9479   \u001b[0m | \u001b[95m0.2541   \u001b[0m | \u001b[95m29.41    \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m0.2404   \u001b[0m | \u001b[0m0.5953   \u001b[0m | \u001b[0m0.01103  \u001b[0m | \u001b[0m11.04    \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.3451   \u001b[0m | \u001b[0m0.5439   \u001b[0m | \u001b[0m33.7     \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m0.5649   \u001b[0m | \u001b[0m0.7125   \u001b[0m | \u001b[0m0.1779   \u001b[0m | \u001b[0m26.08    \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m0.2527   \u001b[0m | \u001b[0m0.4356   \u001b[0m | \u001b[0m0.7286   \u001b[0m | \u001b[0m14.81    \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m0.2591   \u001b[0m | \u001b[0m0.9256   \u001b[0m | \u001b[0m0.3108   \u001b[0m | \u001b[0m27.37    \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m0.2435   \u001b[0m | \u001b[0m0.3902   \u001b[0m | \u001b[0m0.08171  \u001b[0m | \u001b[0m10.65    \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m0.3215   \u001b[0m | \u001b[0m0.7409   \u001b[0m | \u001b[0m0.5089   \u001b[0m | \u001b[0m12.27    \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m0.4725   \u001b[0m | \u001b[0m0.4632   \u001b[0m | \u001b[0m0.6139   \u001b[0m | \u001b[0m48.35    \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m0.5241   \u001b[0m | \u001b[0m0.9174   \u001b[0m | \u001b[0m0.5773   \u001b[0m | \u001b[0m34.34    \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m0.566    \u001b[0m | \u001b[0m0.7547   \u001b[0m | \u001b[0m0.5851   \u001b[0m | \u001b[0m32.47    \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m0.4395   \u001b[0m | \u001b[0m0.9334   \u001b[0m | \u001b[0m0.6633   \u001b[0m | \u001b[0m26.93    \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m0.2511   \u001b[0m | \u001b[0m0.1912   \u001b[0m | \u001b[0m0.4118   \u001b[0m | \u001b[0m31.2     \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m0.4385   \u001b[0m | \u001b[0m0.3893   \u001b[0m | \u001b[0m0.4989   \u001b[0m | \u001b[0m18.64    \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m103      \u001b[0m | \u001b[0m0.2619   \u001b[0m | \u001b[0m0.9404   \u001b[0m | \u001b[0m0.09989  \u001b[0m | \u001b[0m49.22    \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m0.2997   \u001b[0m | \u001b[0m0.6859   \u001b[0m | \u001b[0m0.3914   \u001b[0m | \u001b[0m19.8     \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m0.2681   \u001b[0m | \u001b[0m0.8943   \u001b[0m | \u001b[0m0.41     \u001b[0m | \u001b[0m11.96    \u001b[0m |\n",
      "| \u001b[0m106      \u001b[0m | \u001b[0m0.4411   \u001b[0m | \u001b[0m0.8904   \u001b[0m | \u001b[0m0.4617   \u001b[0m | \u001b[0m21.96    \u001b[0m |\n",
      "| \u001b[0m107      \u001b[0m | \u001b[0m0.2246   \u001b[0m | \u001b[0m0.756    \u001b[0m | \u001b[0m0.1781   \u001b[0m | \u001b[0m21.95    \u001b[0m |\n",
      "| \u001b[0m108      \u001b[0m | \u001b[0m0.3118   \u001b[0m | \u001b[0m0.6112   \u001b[0m | \u001b[0m0.297    \u001b[0m | \u001b[0m34.23    \u001b[0m |\n",
      "| \u001b[0m109      \u001b[0m | \u001b[0m0.4373   \u001b[0m | \u001b[0m0.2088   \u001b[0m | \u001b[0m0.7548   \u001b[0m | \u001b[0m47.02    \u001b[0m |\n",
      "| \u001b[0m110      \u001b[0m | \u001b[0m0.746    \u001b[0m | \u001b[0m0.924    \u001b[0m | \u001b[0m0.1048   \u001b[0m | \u001b[0m30.73    \u001b[0m |\n",
      "| \u001b[0m111      \u001b[0m | \u001b[0m0.2797   \u001b[0m | \u001b[0m0.4381   \u001b[0m | \u001b[0m0.7017   \u001b[0m | \u001b[0m48.68    \u001b[0m |\n",
      "| \u001b[0m112      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.404    \u001b[0m | \u001b[0m0.6838   \u001b[0m | \u001b[0m43.79    \u001b[0m |\n",
      "| \u001b[0m113      \u001b[0m | \u001b[0m0.3124   \u001b[0m | \u001b[0m0.5545   \u001b[0m | \u001b[0m0.007332 \u001b[0m | \u001b[0m43.08    \u001b[0m |\n",
      "| \u001b[0m114      \u001b[0m | \u001b[0m0.3089   \u001b[0m | \u001b[0m0.9412   \u001b[0m | \u001b[0m0.1758   \u001b[0m | \u001b[0m18.26    \u001b[0m |\n",
      "| \u001b[0m115      \u001b[0m | \u001b[0m0.5348   \u001b[0m | \u001b[0m0.7422   \u001b[0m | \u001b[0m0.1152   \u001b[0m | \u001b[0m38.23    \u001b[0m |\n",
      "| \u001b[0m116      \u001b[0m | \u001b[0m0.2306   \u001b[0m | \u001b[0m0.4018   \u001b[0m | \u001b[0m0.2079   \u001b[0m | \u001b[0m12.69    \u001b[0m |\n",
      "| \u001b[0m117      \u001b[0m | \u001b[0m0.7705   \u001b[0m | \u001b[0m0.9957   \u001b[0m | \u001b[0m0.7055   \u001b[0m | \u001b[0m24.87    \u001b[0m |\n",
      "| \u001b[0m118      \u001b[0m | \u001b[0m0.2096   \u001b[0m | \u001b[0m0.8198   \u001b[0m | \u001b[0m0.6362   \u001b[0m | \u001b[0m16.25    \u001b[0m |\n",
      "| \u001b[0m119      \u001b[0m | \u001b[0m0.2364   \u001b[0m | \u001b[0m0.9319   \u001b[0m | \u001b[0m0.2876   \u001b[0m | \u001b[0m15.68    \u001b[0m |\n",
      "| \u001b[0m120      \u001b[0m | \u001b[0m0.7453   \u001b[0m | \u001b[0m0.7027   \u001b[0m | \u001b[0m0.161    \u001b[0m | \u001b[0m26.7     \u001b[0m |\n",
      "| \u001b[0m121      \u001b[0m | \u001b[0m0.2099   \u001b[0m | \u001b[0m0.1605   \u001b[0m | \u001b[0m0.02433  \u001b[0m | \u001b[0m11.77    \u001b[0m |\n",
      "| \u001b[0m122      \u001b[0m | \u001b[0m0.1866   \u001b[0m | \u001b[0m0.23     \u001b[0m | \u001b[0m0.7038   \u001b[0m | \u001b[0m40.92    \u001b[0m |\n",
      "| \u001b[0m123      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.6717   \u001b[0m | \u001b[0m0.6963   \u001b[0m | \u001b[0m39.07    \u001b[0m |\n",
      "| \u001b[0m124      \u001b[0m | \u001b[0m0.5849   \u001b[0m | \u001b[0m0.942    \u001b[0m | \u001b[0m0.05383  \u001b[0m | \u001b[0m45.42    \u001b[0m |\n",
      "| \u001b[0m125      \u001b[0m | \u001b[0m0.7413   \u001b[0m | \u001b[0m0.364    \u001b[0m | \u001b[0m0.0429   \u001b[0m | \u001b[0m40.06    \u001b[0m |\n",
      "| \u001b[0m126      \u001b[0m | \u001b[0m0.2303   \u001b[0m | \u001b[0m0.5798   \u001b[0m | \u001b[0m0.61     \u001b[0m | \u001b[0m24.37    \u001b[0m |\n",
      "| \u001b[0m127      \u001b[0m | \u001b[0m0.2418   \u001b[0m | \u001b[0m0.5977   \u001b[0m | \u001b[0m0.5113   \u001b[0m | \u001b[0m34.13    \u001b[0m |\n",
      "| \u001b[0m128      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.5594   \u001b[0m | \u001b[0m0.7302   \u001b[0m | \u001b[0m37.04    \u001b[0m |\n",
      "| \u001b[0m129      \u001b[0m | \u001b[0m0.3105   \u001b[0m | \u001b[0m0.9276   \u001b[0m | \u001b[0m0.7242   \u001b[0m | \u001b[0m30.93    \u001b[0m |\n",
      "| \u001b[0m130      \u001b[0m | \u001b[0m0.1878   \u001b[0m | \u001b[0m0.2309   \u001b[0m | \u001b[0m0.3502   \u001b[0m | \u001b[0m36.03    \u001b[0m |\n",
      "| \u001b[0m131      \u001b[0m | \u001b[0m0.2413   \u001b[0m | \u001b[0m0.7522   \u001b[0m | \u001b[0m0.7184   \u001b[0m | \u001b[0m47.13    \u001b[0m |\n",
      "| \u001b[0m132      \u001b[0m | \u001b[0m0.4584   \u001b[0m | \u001b[0m0.1276   \u001b[0m | \u001b[0m0.758    \u001b[0m | \u001b[0m27.92    \u001b[0m |\n",
      "| \u001b[0m133      \u001b[0m | \u001b[0m0.2291   \u001b[0m | \u001b[0m0.5265   \u001b[0m | \u001b[0m0.3552   \u001b[0m | \u001b[0m29.5     \u001b[0m |\n",
      "| \u001b[0m134      \u001b[0m | \u001b[0m0.5711   \u001b[0m | \u001b[0m0.7135   \u001b[0m | \u001b[0m0.3648   \u001b[0m | \u001b[0m15.58    \u001b[0m |\n",
      "| \u001b[0m135      \u001b[0m | \u001b[0m0.3428   \u001b[0m | \u001b[0m0.8355   \u001b[0m | \u001b[0m0.05739  \u001b[0m | \u001b[0m47.15    \u001b[0m |\n",
      "| \u001b[0m136      \u001b[0m | \u001b[0m0.5508   \u001b[0m | \u001b[0m0.3732   \u001b[0m | \u001b[0m0.2367   \u001b[0m | \u001b[0m44.43    \u001b[0m |\n",
      "| \u001b[0m137      \u001b[0m | \u001b[0m0.2389   \u001b[0m | \u001b[0m0.8117   \u001b[0m | \u001b[0m0.6429   \u001b[0m | \u001b[0m12.13    \u001b[0m |\n",
      "| \u001b[0m138      \u001b[0m | \u001b[0m0.2265   \u001b[0m | \u001b[0m0.4809   \u001b[0m | \u001b[0m0.5608   \u001b[0m | \u001b[0m25.9     \u001b[0m |\n",
      "| \u001b[0m139      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.8914   \u001b[0m | \u001b[0m0.617    \u001b[0m | \u001b[0m20.74    \u001b[0m |\n",
      "| \u001b[0m140      \u001b[0m | \u001b[0m0.4927   \u001b[0m | \u001b[0m0.2915   \u001b[0m | \u001b[0m0.4042   \u001b[0m | \u001b[0m27.61    \u001b[0m |\n",
      "| \u001b[95m141      \u001b[0m | \u001b[95m0.777    \u001b[0m | \u001b[95m0.5988   \u001b[0m | \u001b[95m0.6457   \u001b[0m | \u001b[95m42.67    \u001b[0m |\n",
      "| \u001b[0m142      \u001b[0m | \u001b[0m0.7411   \u001b[0m | \u001b[0m0.3464   \u001b[0m | \u001b[0m0.07587  \u001b[0m | \u001b[0m28.25    \u001b[0m |\n",
      "| \u001b[0m143      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.4013   \u001b[0m | \u001b[0m0.3341   \u001b[0m | \u001b[0m48.82    \u001b[0m |\n",
      "| \u001b[0m144      \u001b[0m | \u001b[0m0.4409   \u001b[0m | \u001b[0m0.5656   \u001b[0m | \u001b[0m0.6566   \u001b[0m | \u001b[0m21.01    \u001b[0m |\n",
      "| \u001b[0m145      \u001b[0m | \u001b[0m0.3329   \u001b[0m | \u001b[0m0.5533   \u001b[0m | \u001b[0m0.07029  \u001b[0m | \u001b[0m30.48    \u001b[0m |\n",
      "| \u001b[0m146      \u001b[0m | \u001b[0m0.6801   \u001b[0m | \u001b[0m0.3075   \u001b[0m | \u001b[0m0.4941   \u001b[0m | \u001b[0m36.28    \u001b[0m |\n",
      "| \u001b[0m147      \u001b[0m | \u001b[0m0.2242   \u001b[0m | \u001b[0m0.7575   \u001b[0m | \u001b[0m0.2507   \u001b[0m | \u001b[0m20.32    \u001b[0m |\n",
      "| \u001b[0m148      \u001b[0m | \u001b[0m0.6534   \u001b[0m | \u001b[0m0.7405   \u001b[0m | \u001b[0m0.0848   \u001b[0m | \u001b[0m37.14    \u001b[0m |\n",
      "| \u001b[0m149      \u001b[0m | \u001b[0m0.7722   \u001b[0m | \u001b[0m0.9166   \u001b[0m | \u001b[0m0.122    \u001b[0m | \u001b[0m22.58    \u001b[0m |\n",
      "| \u001b[0m150      \u001b[0m | \u001b[0m0.4598   \u001b[0m | \u001b[0m0.7543   \u001b[0m | \u001b[0m0.4452   \u001b[0m | \u001b[0m36.97    \u001b[0m |\n",
      "| \u001b[0m151      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.3289   \u001b[0m | \u001b[0m0.4327   \u001b[0m | \u001b[0m32.95    \u001b[0m |\n",
      "| \u001b[0m152      \u001b[0m | \u001b[0m0.2561   \u001b[0m | \u001b[0m0.6865   \u001b[0m | \u001b[0m0.01399  \u001b[0m | \u001b[0m28.56    \u001b[0m |\n",
      "| \u001b[0m153      \u001b[0m | \u001b[0m0.1999   \u001b[0m | \u001b[0m0.1578   \u001b[0m | \u001b[0m0.5356   \u001b[0m | \u001b[0m22.44    \u001b[0m |\n",
      "| \u001b[0m154      \u001b[0m | \u001b[0m0.3002   \u001b[0m | \u001b[0m0.8043   \u001b[0m | \u001b[0m0.5226   \u001b[0m | \u001b[0m21.32    \u001b[0m |\n",
      "| \u001b[0m155      \u001b[0m | \u001b[0m0.2265   \u001b[0m | \u001b[0m0.5177   \u001b[0m | \u001b[0m0.6964   \u001b[0m | \u001b[0m45.42    \u001b[0m |\n",
      "| \u001b[0m156      \u001b[0m | \u001b[0m0.2755   \u001b[0m | \u001b[0m0.8942   \u001b[0m | \u001b[0m0.4751   \u001b[0m | \u001b[0m38.21    \u001b[0m |\n",
      "| \u001b[0m157      \u001b[0m | \u001b[0m0.2536   \u001b[0m | \u001b[0m0.8073   \u001b[0m | \u001b[0m0.0334   \u001b[0m | \u001b[0m10.64    \u001b[0m |\n",
      "| \u001b[0m158      \u001b[0m | \u001b[0m0.2347   \u001b[0m | \u001b[0m0.7342   \u001b[0m | \u001b[0m0.4666   \u001b[0m | \u001b[0m12.45    \u001b[0m |\n",
      "| \u001b[0m159      \u001b[0m | \u001b[0m0.5495   \u001b[0m | \u001b[0m0.8416   \u001b[0m | \u001b[0m0.1941   \u001b[0m | \u001b[0m18.77    \u001b[0m |\n",
      "| \u001b[0m160      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.708    \u001b[0m | \u001b[0m0.5776   \u001b[0m | \u001b[0m16.72    \u001b[0m |\n",
      "| \u001b[0m161      \u001b[0m | \u001b[0m0.2257   \u001b[0m | \u001b[0m0.7334   \u001b[0m | \u001b[0m0.2548   \u001b[0m | \u001b[0m20.8     \u001b[0m |\n",
      "| \u001b[0m162      \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m0.351    \u001b[0m | \u001b[0m0.7641   \u001b[0m | \u001b[0m31.93    \u001b[0m |\n",
      "| \u001b[0m163      \u001b[0m | \u001b[0m0.4484   \u001b[0m | \u001b[0m0.1493   \u001b[0m | \u001b[0m0.0635   \u001b[0m | \u001b[0m45.46    \u001b[0m |\n",
      "| \u001b[0m164      \u001b[0m | \u001b[0m0.3172   \u001b[0m | \u001b[0m0.9245   \u001b[0m | \u001b[0m0.05984  \u001b[0m | \u001b[0m33.43    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/users/karsten/.local/lib/python3.9/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (0.13787494994592095, 0.008485200576467114, 41.67448229179727)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/lib/condor/execute/dir_1357265/ipykernel_1357405/1298557552.py\", line 4, in <module>\n",
      "    optimizer.maximize(\n",
      "  File \"/Users/users/karsten/.local/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\", line 305, in maximize\n",
      "    self.probe(x_probe, lazy=False)\n",
      "  File \"/Users/users/karsten/.local/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\", line 200, in probe\n",
      "    self._space.probe(params)\n",
      "  File \"/Users/users/karsten/.local/lib/python3.9/site-packages/bayes_opt/target_space.py\", line 194, in probe\n",
      "    target = self.target_func(**params)\n",
      "  File \"/var/lib/condor/execute/dir_1357265/ipykernel_1357405/1236558146.py\", line 16, in optimise_xgboost\n",
      "    bst = lgb.train(param, train_data, valid_sets=[validation_data], early_stopping_rounds=20, verbose_eval=False)\n",
      "  File \"/Users/users/karsten/.local/lib/python3.9/site-packages/lightgbm/engine.py\", line 316, in train\n",
      "    booster.model_from_string(booster.model_to_string(), verbose='_silent_false').free_dataset()\n",
      "  File \"/Users/users/karsten/.local/lib/python3.9/site-packages/lightgbm/basic.py\", line 3410, in model_to_string\n",
      "    _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/inspect.py\", line 746, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.13787494994592095, 0.008485200576467114, 41.67448229179727)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/var/lib/condor/execute/dir_1357265/ipykernel_1357405/1298557552.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     optimizer.maximize(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/lib/condor/execute/dir_1357265/ipykernel_1357405/1236558146.py\u001b[0m in \u001b[0;36moptimise_xgboost\u001b[0;34m(num_leaves, learning_rate, colsample_bytree)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_training_booster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_silent_false'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mmodel_to_string\u001b[0;34m(self, num_iteration, start_iteration, importance_type)\u001b[0m\n\u001b[1;32m   3409\u001b[0m             \u001b[0mptr_string_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddressof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3410\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n\u001b[0m\u001b[1;32m   3411\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Software/users/modules/7/software/anaconda3/2021.11/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    optimizer.maximize(\n",
    "        init_points=10,\n",
    "        n_iter=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac1f1c",
   "metadata": {},
   "source": [
    "## MIGHTEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "836c4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "mightee_data = pd.read_csv(\"../../../Data/MIGHTEE/Classification/final_gaussian_radio_more.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c7556b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of rows: 4370\n"
     ]
    }
   ],
   "source": [
    "# Dropping nan classifications\n",
    "mightee_data = mightee_data[mightee_data['Classification'].notna()]\n",
    "\n",
    "# Dropping quasar-like radio AGN / high-excitation radio galaxy\n",
    "#mightee_data = mightee_data[mightee_data['Classification'] != 'star-forming galaxy']\n",
    "print(\"Amount of rows:\", len(mightee_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3cad823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mightee_X = mightee_data[[c for c in mightee_data.columns if c != 'Classification']]\n",
    "mightee_y = mightee_data[['Classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d22656e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mightee_X = mightee_X[['Z_BEST', 'ch1_flux_corr', 'ch2_flux_corr', 'ch3_flux_corr',\n",
    "       'ch4_flux_corr', 'F_MIPS_24', 'F_PACS_100', 'F_PACS_160',\n",
    "       'F_SPIRE_250', 'F_SPIRE_350', 'F_SPIRE_500', 'Ks_flux_corr',\n",
    "       'H_flux_corr', 'J_flux_corr', 'i_flux_corr', 'r_flux_corr',\n",
    "       'u_flux_corr', 'z_flux_corr', 'y_flux_corr', 'NUV_flux_corr',\n",
    "       #'FUV_flux_corr', \n",
    "                       'Total_flux', 'Peak_flux']]\n",
    "\n",
    "mightee_X[['I_flux_corr', 'R_flux_corr']] = mightee_X[['i_flux_corr', 'r_flux_corr']]\n",
    "mightee_X = mightee_X.drop(columns=['i_flux_corr', 'r_flux_corr'])\n",
    "\n",
    "# Adding nans to missing columns\n",
    "mightee_X[['Bw_flux_corr', 'K_flux_corr', 'g_flux_corr', 'nb921_hsc_flux_corr']] = np.nan\n",
    "\n",
    "# Changing order\n",
    "mightee_X = mightee_X[['Total_flux', 'Peak_flux', \n",
    "                       'NUV_flux_corr', 'u_flux_corr', \n",
    "                       'Bw_flux_corr', 'R_flux_corr', \n",
    "                       'I_flux_corr', 'z_flux_corr', \n",
    "                       'y_flux_corr', 'J_flux_corr', \n",
    "                       'H_flux_corr', 'K_flux_corr', \n",
    "                       'Ks_flux_corr', 'ch1_flux_corr', \n",
    "                       'ch2_flux_corr', 'ch3_flux_corr', \n",
    "                       'ch4_flux_corr', 'F_MIPS_24', 'F_PACS_100', \n",
    "                       'F_PACS_160', 'F_SPIRE_250', 'F_SPIRE_350', \n",
    "                       'F_SPIRE_500', 'Z_BEST', \n",
    "                       'g_flux_corr', 'nb921_hsc_flux_corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c2c9aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/lib/condor/execute/dir_1357265/ipykernel_1357405/2572876279.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mightee_y['AGN'] =  mightee_y.apply(AGN, axis=1, result_type='expand')\n"
     ]
    }
   ],
   "source": [
    "mightee_y['AGN'] =  mightee_y.apply(AGN, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "fcf94183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7843    0.7900    0.7871      2790\n",
      "           1     0.6244    0.6165    0.6204      1580\n",
      "\n",
      "    accuracy                         0.7272      4370\n",
      "   macro avg     0.7044    0.7032    0.7038      4370\n",
      "weighted avg     0.7265    0.7272    0.7268      4370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bst.predict(mightee_X)\n",
    "#pred = (pred-pred.min())\n",
    "#pred = pred/pred.max()\n",
    "pred = np.rint(pred)\n",
    "print(classification_report(mightee_y['AGN'], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e8090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Anaconda3 - 2021.11",
   "language": "python",
   "name": "python3-2021.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
